{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3004,"databundleVersionId":861823,"sourceType":"competition"}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-16T01:58:56.392336Z","iopub.execute_input":"2026-02-16T01:58:56.392645Z","iopub.status.idle":"2026-02-16T01:58:56.398851Z","shell.execute_reply.started":"2026-02-16T01:58:56.392618Z","shell.execute_reply":"2026-02-16T01:58:56.398245Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/digit-recognizer/sample_submission.csv\n/kaggle/input/digit-recognizer/train.csv\n/kaggle/input/digit-recognizer/test.csv\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# Imports\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T01:58:56.400242Z","iopub.execute_input":"2026-02-16T01:58:56.400607Z","iopub.status.idle":"2026-02-16T01:58:56.412586Z","shell.execute_reply.started":"2026-02-16T01:58:56.400581Z","shell.execute_reply":"2026-02-16T01:58:56.411950Z"}},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"code","source":"class DigitRecognizerDataset(Dataset):\n    def __init__(self, dataframe, is_test=False, transform=None):\n        self.is_test = is_test\n        self.transform = transform\n        \n        if not self.is_test:\n            self.labels = torch.tensor(dataframe.iloc[:, 0].values, dtype=torch.long)\n            data = dataframe.iloc[:, 1:].values\n        else:\n            self.labels = None \n            data = dataframe.values\n            \n        # Features are reshaped to (C, H, W)\n        self.features = torch.tensor(data, dtype=torch.float32).view(-1, 1, 28, 28)\n\n    def __len__(self):\n        return len(self.features)\n\n    def __getitem__(self, idx):\n        image = self.features[idx]\n        \n        # Normalize to [0, 1] range\n        image = image / 255.0\n        \n        # Apply augmentation if provided\n        if self.transform:\n            image = self.transform(image)\n            \n        if self.is_test:\n            return image\n        return image, self.labels[idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T01:58:56.413390Z","iopub.execute_input":"2026-02-16T01:58:56.413643Z","iopub.status.idle":"2026-02-16T01:58:56.424795Z","shell.execute_reply.started":"2026-02-16T01:58:56.413621Z","shell.execute_reply":"2026-02-16T01:58:56.424168Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"KAGGLE = True\nif KAGGLE:\n    train_set_filepath = '/kaggle/input/digit-recognizer/train.csv'\n    test_set_filepath = '/kaggle/input/digit-recognizer/test.csv'\nelse:\n    train_set_filepath = os.path.join(os.getcwd(), 'train.csv')\n    test_set_filepath = os.path.join(os.getcwd(), 'test.csv')\n\n# Load datasets\nbase_train_df = pd.read_csv(train_set_filepath)\nif os.path.exists(test_set_filepath):\n    base_test_df = pd.read_csv(test_set_filepath)\nelse:\n    base_test_df = None\n\n# Only the train set has labels so we need to split that into our real train and test sets\ntrain_df, val_df = train_test_split(base_train_df, test_size=0.2, random_state=42)\n\ntrain_transforms = transforms.Compose([\n    transforms.RandomRotation(10), # Rotate up to 10 degrees\n    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)), # Shift and Zoom\n])\n\n# Convert to torch datasets\ntrain_set = DigitRecognizerDataset(train_df, is_test=False, transform=train_transforms)\nval_set = DigitRecognizerDataset(val_df, is_test=False)\nif base_test_df is not None:\n    test_set = DigitRecognizerDataset(base_test_df, is_test=True)\nelse:\n    test_set = None\n\n# Create data loaders\ntrain_loader = DataLoader(train_set, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_set, batch_size=32, shuffle=False)\nif test_set is not None:\n    test_loader = DataLoader(test_set, batch_size=32, shuffle=False)\nelse:\n    test_loader = None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T01:58:56.425827Z","iopub.execute_input":"2026-02-16T01:58:56.426121Z","iopub.status.idle":"2026-02-16T01:58:59.812403Z","shell.execute_reply.started":"2026-02-16T01:58:56.426093Z","shell.execute_reply":"2026-02-16T01:58:59.811614Z"}},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        \n        # Block 1: Input 1x28x28 -> Output 32x14x14\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n        self.bn1 = nn.BatchNorm2d(32)\n        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n        self.bn2 = nn.BatchNorm2d(32)\n        self.pool1 = nn.MaxPool2d(2)\n        self.drop1 = nn.Dropout2d(0.25)\n\n        # Block 2: Input 32x14x14 -> Output 64x7x7\n        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.bn3 = nn.BatchNorm2d(64)\n        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n        self.bn4 = nn.BatchNorm2d(64)\n        self.pool2 = nn.MaxPool2d(2)\n        self.drop2 = nn.Dropout2d(0.25)\n\n        # Fully Connected Classifier\n        self.fc1 = nn.Linear(64 * 7 * 7, 256)\n        self.bn5 = nn.BatchNorm1d(256)\n        self.drop3 = nn.Dropout(0.5)\n        self.fc2 = nn.Linear(256, 10)\n\n    def forward(self, x):\n        # Block 1\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = self.pool1(x)\n        x = self.drop1(x)\n\n        # Block 2\n        x = F.relu(self.bn3(self.conv3(x)))\n        x = F.relu(self.bn4(self.conv4(x)))\n        x = self.pool2(x)\n        x = self.drop2(x)\n\n        # Flatten and Classify\n        x = torch.flatten(x, 1)\n        x = F.relu(self.bn5(self.fc1(x)))\n        x = self.drop3(x)\n        x = self.fc2(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T01:58:59.814332Z","iopub.execute_input":"2026-02-16T01:58:59.814570Z","iopub.status.idle":"2026-02-16T01:58:59.821939Z","shell.execute_reply.started":"2026-02-16T01:58:59.814549Z","shell.execute_reply":"2026-02-16T01:58:59.821279Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"DEVICE = torch.device('cpu')\nif torch.cuda.is_available():\n    DEVICE = torch.device('cuda')\nelif torch.backends.mps.is_available():\n    DEVICE = torch.device('mps')\nprint(f\"Using device: {DEVICE}\")\n\ncriterion = nn.CrossEntropyLoss()\n\nNUM_MODELS = 5 # Number of models in ensemble\nmodels = []\noptimizers = []\nschedulers = []\n\nfor i in range(NUM_MODELS):\n    # Set a unique seed for each model instance\n    torch.manual_seed(42 + i) \n    \n    model = CNN().to(DEVICE) \n    models.append(model)\n    \n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    optimizers.append(optimizer)\n    \n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2)\n    schedulers.append(scheduler)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T01:58:59.822801Z","iopub.execute_input":"2026-02-16T01:58:59.823098Z","iopub.status.idle":"2026-02-16T01:58:59.877928Z","shell.execute_reply.started":"2026-02-16T01:58:59.823064Z","shell.execute_reply":"2026-02-16T01:58:59.877208Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":30},{"cell_type":"markdown","source":"## Train","metadata":{}},{"cell_type":"code","source":"# Test\ndef test_model(model):\n    model.eval() # Set model to evaluation mode\n    correct = 0\n    total = 0\n    val_loss = 0.0\n    with torch.no_grad():\n        for data in val_loader:\n            images, labels = data\n            images = images.to(DEVICE)\n            labels = labels.to(DEVICE)\n            outputs = model(images)\n            loss = criterion(outputs, labels) # Calculate loss\n            val_loss += loss.item()\n            \n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    \n    avg_loss = val_loss / len(val_loader)\n    print(f'Accuracy: {100 * correct / total:.2f}% | Val Loss: {avg_loss:.4f}')\n    return avg_loss # Return this for the scheduler","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T01:58:59.878777Z","iopub.execute_input":"2026-02-16T01:58:59.879029Z","iopub.status.idle":"2026-02-16T01:58:59.884603Z","shell.execute_reply.started":"2026-02-16T01:58:59.879009Z","shell.execute_reply":"2026-02-16T01:58:59.883965Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"# Train\nEPOCHS = 30\nfor m_idx, cnn in enumerate(models):\n    print(f\"Training Model {m_idx + 1}/{len(models)}...\")\n    optimizer = optimizers[m_idx]\n    scheduler = schedulers[m_idx]\n    \n    for epoch in range(EPOCHS):\n        cnn.train() # Set model back to training mode\n        running_loss = 0.0\n        for i, data in enumerate(train_loader, 0):\n            inputs, labels = data\n            inputs = inputs.to(DEVICE)\n            labels = labels.to(DEVICE)\n            optimizer.zero_grad()\n            outputs = cnn(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            # scheduler.step() # needed if using OneCycleLR\n    \n            running_loss += loss.item()\n            if i % 100 == 99:\n                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 100:.3f}')\n                running_loss = 0.0\n    \n        # Run validation and get the loss\n        current_val_loss = test_model(cnn)\n        \n        # Step the scheduler based on the validation loss\n        scheduler.step(current_val_loss)\n        \n        current_lr = optimizer.param_groups[0]['lr']\n        print(f'End of Epoch {epoch + 1} - Learning Rate: {current_lr}')\n\n    print(f'Finished Training Model {m_idx + 1}')\n\nprint('Finished Training')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T01:58:59.885591Z","iopub.execute_input":"2026-02-16T01:58:59.885920Z","iopub.status.idle":"2026-02-16T02:01:45.425041Z","shell.execute_reply.started":"2026-02-16T01:58:59.885877Z","shell.execute_reply":"2026-02-16T02:01:45.424258Z"}},"outputs":[{"name":"stdout","text":"Training Model 1/5...\n[1,   100] loss: 1.182\n[1,   200] loss: 0.527\n[1,   300] loss: 0.402\n[1,   400] loss: 0.306\n[1,   500] loss: 0.274\n[1,   600] loss: 0.229\n[1,   700] loss: 0.235\n[1,   800] loss: 0.217\n[1,   900] loss: 0.195\n[1,  1000] loss: 0.215\nAccuracy: 98.62% | Val Loss: 0.0435\nEnd of Epoch 1 - Learning Rate: 0.001\nFinished Training Model 1\nTraining Model 2/5...\n[1,   100] loss: 1.177\n[1,   200] loss: 0.546\n[1,   300] loss: 0.393\n[1,   400] loss: 0.317\n[1,   500] loss: 0.274\n[1,   600] loss: 0.249\n[1,   700] loss: 0.229\n[1,   800] loss: 0.195\n[1,   900] loss: 0.193\n[1,  1000] loss: 0.171\nAccuracy: 98.61% | Val Loss: 0.0480\nEnd of Epoch 1 - Learning Rate: 0.001\nFinished Training Model 2\nTraining Model 3/5...\n[1,   100] loss: 1.172\n[1,   200] loss: 0.528\n[1,   300] loss: 0.393\n[1,   400] loss: 0.315\n[1,   500] loss: 0.272\n[1,   600] loss: 0.255\n[1,   700] loss: 0.224\n[1,   800] loss: 0.223\n[1,   900] loss: 0.193\n[1,  1000] loss: 0.207\nAccuracy: 98.74% | Val Loss: 0.0434\nEnd of Epoch 1 - Learning Rate: 0.001\nFinished Training Model 3\nTraining Model 4/5...\n[1,   100] loss: 1.162\n[1,   200] loss: 0.530\n[1,   300] loss: 0.381\n[1,   400] loss: 0.307\n[1,   500] loss: 0.288\n[1,   600] loss: 0.244\n[1,   700] loss: 0.213\n[1,   800] loss: 0.204\n[1,   900] loss: 0.196\n[1,  1000] loss: 0.166\nAccuracy: 98.68% | Val Loss: 0.0438\nEnd of Epoch 1 - Learning Rate: 0.001\nFinished Training Model 4\nTraining Model 5/5...\n[1,   100] loss: 1.154\n[1,   200] loss: 0.569\n[1,   300] loss: 0.387\n[1,   400] loss: 0.307\n[1,   500] loss: 0.273\n[1,   600] loss: 0.247\n[1,   700] loss: 0.219\n[1,   800] loss: 0.209\n[1,   900] loss: 0.207\n[1,  1000] loss: 0.175\nAccuracy: 98.58% | Val Loss: 0.0434\nEnd of Epoch 1 - Learning Rate: 0.001\nFinished Training Model 5\nFinished Training\n","output_type":"stream"}],"execution_count":32},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"if test_loader is not None:\n    # Submission\n    submission_data = {'ImageId': [], 'Label': []}\n    \n    # Set all models to eval mode\n    for cnn in models:\n        cnn.eval()\n    \n    with torch.no_grad():\n        idx = 1\n        for images in test_loader:\n            images = images.to(DEVICE)\n            \n            # Initialize an empty tensor to store accumulated predictions\n            # Shape: [batch_size, num_classes]\n            ensemble_logits = torch.zeros((images.size(0), 10)).to(DEVICE) \n            \n            for cnn in models:\n                outputs = cnn(images)\n                ensemble_logits += outputs # Summing the logits\n            \n            # Get the index of the max accumulated log-probability\n            _, predicted = torch.max(ensemble_logits, 1)\n    \n            preds = predicted.cpu().numpy()\n    \n            for p in preds:\n                submission_data['ImageId'].append(idx)\n                submission_data['Label'].append(p)\n                idx += 1\n    \n    # Save to csv\n    submission_df = pd.DataFrame(submission_data)\n    submission_df.to_csv('submission.csv', index=False)\n    print(\"Submission file saved!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T02:03:05.943762Z","iopub.execute_input":"2026-02-16T02:03:05.944451Z","iopub.status.idle":"2026-02-16T02:03:10.127852Z","shell.execute_reply.started":"2026-02-16T02:03:05.944418Z","shell.execute_reply":"2026-02-16T02:03:10.127081Z"}},"outputs":[{"name":"stdout","text":"Submission file saved!\n","output_type":"stream"}],"execution_count":34},{"cell_type":"markdown","source":"## Verification","metadata":{}},{"cell_type":"code","source":"if submission_df is not None:\n    # 1. Check for missing values\n    missing_values = submission_df.isnull().sum().sum()\n    \n    # 2. Check for correct label range (0-9)\n    invalid_labels = submission_df[(submission_df['Label'] < 0) | (submission_df['Label'] > 9)]\n    \n    # 3. Final Verification Report\n    print(\"--- Submission Verification ---\")\n    print(f\"Total Rows: {len(submission_df)}\")\n    print(f\"Missing Values: {missing_values}\")\n    print(f\"Invalid Labels Found: {len(invalid_labels)}\")\n    print(f\"Column Names: {list(submission_df.columns)}\")\n    \n    if len(submission_df) == len(base_test_df) and missing_values == 0 and len(invalid_labels) == 0:\n        print(\"\\n✅ Verification Passed! Your file is ready for submission.\")\n    else:\n        print(\"\\n❌ Verification Failed. Please check the counts above.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T02:03:12.067769Z","iopub.execute_input":"2026-02-16T02:03:12.068310Z","iopub.status.idle":"2026-02-16T02:03:12.076154Z","shell.execute_reply.started":"2026-02-16T02:03:12.068281Z","shell.execute_reply":"2026-02-16T02:03:12.075257Z"}},"outputs":[{"name":"stdout","text":"--- Submission Verification ---\nTotal Rows: 28000\nMissing Values: 0\nInvalid Labels Found: 0\nColumn Names: ['ImageId', 'Label']\n\n✅ Verification Passed! Your file is ready for submission.\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"if submission_df is not None:\n    # Get one batch from the test loader\n    images = next(iter(test_loader))\n    outputs = cnn(images.to(DEVICE))\n    _, predicted = torch.max(outputs, 1)\n    \n    # Plot the first image in the batch\n    plt.imshow(images[0].reshape(28, 28), cmap='gray')\n    plt.title(f'Predicted Label: {predicted[0].item()}')\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T02:04:00.571963Z","iopub.execute_input":"2026-02-16T02:04:00.572324Z","iopub.status.idle":"2026-02-16T02:04:00.685838Z","shell.execute_reply.started":"2026-02-16T02:04:00.572296Z","shell.execute_reply":"2026-02-16T02:04:00.685230Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAaAAAAGzCAYAAABpdMNsAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAJPhJREFUeJzt3X90VPWd//FX+JEhQDKQ3xmBGFDA8vMYJUQwYImEgK6A2wr1dIN2FWhAMGvp0lP5oZ6T1W4trSLaH0u2VFQ4p8DRdXEhEKgU6BJhKaxQkg0lLiQox8xgYhJIPt8/+DLLkAS4YSafJDwf53zOydz7ec99z/WaF3fmzk2YMcYIAIA21sV2AwCAWxMBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBhE7n9ttv15w5c/yPi4qKFBYWpqKiIms9Xe3qHtvCxIkTNXz48KA+p43Xgc6DAEJQFRQUKCwszD969OihwYMHa8GCBaqsrLTdniMffvihVqxYYbWHsLAwLViwwGoPoXLs2DEtWbJEo0ePVmRkpJKSkjRt2jQdOHDAdmtoIwQQQuKFF17QunXr9Prrr+u+++7TmjVrlJ6erpqamjbvJSMjQ19//bUyMjIc1X344YdauXJliLrCr3/9a/3qV7/SPffco5/+9KfKy8vT8ePHNXbsWG3fvt12e2gD3Ww3gM4pOztb99xzjyTp7//+7xUTE6NXX31VW7Zs0ezZs5utqa6uVq9evYLeS5cuXdSjR4+gPy9uzuzZs7VixQr17t3bv+zJJ5/UXXfdpRUrVigzM9Nid2gLnAGhTXzzm9+UJJWVlUmS5syZo969e6u0tFRTp05VZGSkHn/8cUlSY2OjVq1apWHDhqlHjx5KSEjQ3Llz9eWXXwY8pzFGL730kvr166eePXvqgQce0NGjR5tsu6XPgPbv36+pU6eqb9++6tWrl0aOHKmf//zn/v5Wr14tSQFvKV4W7B5vxpYtWzRt2jR5PB65XC4NGjRIL774ohoaGpqdX1xcrPvuu08RERFKSUnRm2++2WROXV2dli9frjvuuEMul0v9+/fXkiVLVFdXd91+SktLVVpaet15qampAeEjSTExMbr//vv16aefXrceHR9nQGgTl38hxcTE+JddvHhRWVlZGj9+vP75n/9ZPXv2lCTNnTtXBQUFeuKJJ/TMM8+orKxMr7/+ug4ePKg9e/aoe/fukqRly5bppZde0tSpUzV16lR98sknmjx5surr66/bz7Zt2/TQQw8pKSlJixYtUmJioj799FN98MEHWrRokebOnavTp09r27ZtWrduXZP6tujxRhUUFKh3797Ky8tT7969tWPHDi1btkw+n08/+clPAuZ++eWXmjp1qr797W9r9uzZ2rBhg+bPn6/w8HA9+eSTki6F69/8zd/o448/1tNPP6277rpLf/7zn/Wzn/1Mf/nLX7R58+Zr9jNp0iRJ0smTJ1v1eioqKhQbG9uqWnQwBgiitWvXGklm+/bt5vPPPzfl5eXm3XffNTExMSYiIsJ89tlnxhhjcnJyjCTzj//4jwH1f/jDH4wk8/bbbwcs37p1a8Dys2fPmvDwcDNt2jTT2Njon/ejH/3ISDI5OTn+ZTt37jSSzM6dO40xxly8eNGkpKSY5ORk8+WXXwZs58rnys3NNc39LxKKHlsiyeTm5l5zTk1NTZNlc+fONT179jS1tbX+ZRMmTDCSzE9/+lP/srq6OjN69GgTHx9v6uvrjTHGrFu3znTp0sX84Q9/CHjON99800gye/bs8S9LTk5u8jqSk5NNcnLydV9bc3bv3m3CwsLM888/36p6dCy8BYeQyMzMVFxcnPr3769Zs2apd+/e2rRpk2677baAefPnzw94vHHjRrndbj344IP64osv/OPy2zU7d+6UJG3fvl319fVauHBhwFtjixcvvm5vBw8eVFlZmRYvXqw+ffoErLvyuVrSFj06ERER4f/5/Pnz+uKLL3T//ferpqZGx44dC5jbrVs3zZ071/84PDxcc+fO1dmzZ1VcXOx/fXfddZeGDh0a8Pouv416+fW15OTJk606+zl79qy+853vKCUlRUuWLHFcj46Ht+AQEqtXr9bgwYPVrVs3JSQkaMiQIerSJfDfO926dVO/fv0Clp04cUJer1fx8fHNPu/Zs2clSX/9618lSXfeeWfA+ri4OPXt2/eavV1+O7C134lpix6dOHr0qH784x9rx44d8vl8Aeu8Xm/AY4/H0+RCj8GDB0u6FBxjx47ViRMn9OmnnyouLq7Z7V1+fcFUXV2thx56SOfPn9fHH3/c5LMhdE4EEEJizJgx/qvgWuJyuZqEUmNjo+Lj4/X22283W9PSL8W21J56rKqq0oQJExQVFaUXXnhBgwYNUo8ePfTJJ5/ohz/8oRobGx0/Z2Njo0aMGKFXX3212fX9+/e/2bYD1NfXa+bMmTp8+LA++uijoH9ZFu0XAYR2ZdCgQdq+fbvGjRsX8NbS1ZKTkyVdOhsZOHCgf/nnn3/e5Eq05rYhSUeOHLnmpb4tvR3XFj3eqKKiIp07d06///3vA77ndPlqw6udPn26yeXuf/nLXyRduquBdOn1/dd//ZcmTZp0Q29J3ozGxkb93d/9nQoLC7VhwwZNmDAhpNtD+8JnQGhXvv3tb6uhoUEvvvhik3UXL15UVVWVpEufMXXv3l2vvfaajDH+OatWrbruNu6++26lpKRo1apV/ue77MrnuvxL+uo5bdHjjeratWuTvuvr6/XGG280O//ixYt66623Aua+9dZbiouLU2pqqqRLr+9///d/9atf/apJ/ddff63q6upr9nSjl2FL0sKFC/Xee+/pjTfe0MyZM2+oBp0HZ0BoVyZMmKC5c+cqPz9fhw4d0uTJk9W9e3edOHFCGzdu1M9//nP97d/+reLi4vTcc88pPz9fDz30kKZOnaqDBw/q3//93697CW+XLl20Zs0aPfzwwxo9erSeeOIJJSUl6dixYzp69Kg++ugjSfL/Qn7mmWeUlZWlrl27atasWW3S45UOHDigl156qcnyiRMn6r777lPfvn2Vk5OjZ555RmFhYVq3bl1AIF3J4/Ho5Zdf1smTJzV48GC99957OnTokH75y1/6Lx3/7ne/qw0bNmjevHnauXOnxo0bp4aGBh07dkwbNmzQRx99dM23V2/0MuxVq1bpjTfeUHp6unr27Knf/e53AetnzJgRki8mox2xeg0eOp3Ll2H/53/+5zXn5eTkmF69erW4/pe//KVJTU01ERERJjIy0owYMcIsWbLEnD592j+noaHBrFy50iQlJZmIiAgzceJEc+TIkSaXBl99GfZlH3/8sXnwwQdNZGSk6dWrlxk5cqR57bXX/OsvXrxoFi5caOLi4kxYWFiTS7KD2WNLJLU4XnzxRWOMMXv27DFjx441ERERxuPxmCVLlpiPPvqoyWueMGGCGTZsmDlw4IBJT083PXr0MMnJyeb1119vst36+nrz8ssvm2HDhhmXy2X69u1rUlNTzcqVK43X6/XPu5nLsC9fit/SKCsru+5zoGMLM6aFfyoBABBCfAYEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAV7e6LqI2NjTp9+rQiIyNDfhsQAEDwGWN0/vx5eTyeJvd7vFK7C6DTp08H/WaHAIC2V15e3uSO91dqd2/BRUZG2m4BABAE1/t9HrIAWr16tW6//Xb16NFDaWlp+tOf/nRDdbztBgCdw/V+n4ckgN577z3l5eVp+fLl+uSTTzRq1ChlZWWF5A9ZAQA6qFDcYG7MmDEBf8e+oaHBeDwek5+ff91ar9d7zRsUMhgMBqNjjCtvXNucoJ8B1dfXq7i4OOAPfXXp0kWZmZnau3dvk/l1dXXy+XwBAwDQ+QU9gL744gs1NDQoISEhYHlCQoIqKiqazM/Pz5fb7fYProADgFuD9avgli5dKq/X6x/l5eW2WwIAtIGgfw8oNjZWXbt2VWVlZcDyyspKJSYmNpnvcrnkcrmC3QYAoJ0L+hlQeHi4UlNTVVhY6F/W2NiowsJCpaenB3tzAIAOKiR3QsjLy1NOTo7uuecejRkzRqtWrVJ1dbWeeOKJUGwOANABhSSAHnvsMX3++edatmyZKioqNHr0aG3durXJhQkAgFtXmDHG2G7iSj6fT26323YbAICb5PV6FRUV1eJ661fBAQBuTQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWdLPdAHA9PXv2dFzjcrlC0IldEydOdFzz5JNPBr+RFixevNhxTWlpafAbQYfBGRAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWMHNSNHurVy50nFNXl5eCDrBtTz//PO2W0AHwxkQAMAKAggAYEXQA2jFihUKCwsLGEOHDg32ZgAAHVxIPgMaNmyYtm/f/n8b6cZHTQCAQCFJhm7duikxMTEUTw0A6CRC8hnQiRMn5PF4NHDgQD3++OM6depUi3Pr6urk8/kCBgCg8wt6AKWlpamgoEBbt27VmjVrVFZWpvvvv1/nz59vdn5+fr7cbrd/9O/fP9gtAQDaoaAHUHZ2tr71rW9p5MiRysrK0ocffqiqqipt2LCh2flLly6V1+v1j/Ly8mC3BABoh0J+dUCfPn00ePBglZSUNLve5XLJ5XKFug0AQDsT8u8BffXVVyotLVVSUlKoNwUA6ECCHkDPPfecdu3apZMnT+qPf/yjZsyYoa5du2r27NnB3hQAoAML+ltwn332mWbPnq1z584pLi5O48eP1759+xQXFxfsTQEAOrAwY4yx3cSVfD6f3G637TYQIuPHj3dc88477ziu8Xg8jmtwcw4fPuy4pqamxnHN/PnzHde0pjfcPK/Xq6ioqBbXcy84AIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCm5GiTR09etRxzdChQ0PQCTqqU6dOOa751re+1aptHThwoFV1uISbkQIA2iUCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCs6Ga7AdxaFixY4Lhm/fr1jmvi4+Md17SlRYsWOa7Zvn17CDpp3rRp0xzXrFixwnFNz549HdcMGDDAcc3MmTMd10jSwYMHHdc0NDS0alu3Is6AAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMCKMGOMsd3ElXw+n9xut+020I5MmDDBcc3dd98dgk6C5/3333dcU1JSEoJOgqe4uNhxzejRo4PfSBBFR0c7rvF6vSHopGPyer2KiopqcT1nQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBTcjBRAUY8eOdVyzZ8+eEHQSPNyM9OZwM1IAQLtEAAEArHAcQLt379bDDz8sj8ejsLAwbd68OWC9MUbLli1TUlKSIiIilJmZqRMnTgSrXwBAJ+E4gKqrqzVq1CitXr262fWvvPKKfvGLX+jNN9/U/v371atXL2VlZam2tvammwUAdB7dnBZkZ2crOzu72XXGGK1atUo//vGP9cgjj0iSfvvb3yohIUGbN2/WrFmzbq5bAECnEdTPgMrKylRRUaHMzEz/MrfbrbS0NO3du7fZmrq6Ovl8voABAOj8ghpAFRUVkqSEhISA5QkJCf51V8vPz5fb7faP/v37B7MlAEA7Zf0quKVLl8rr9fpHeXm57ZYAAG0gqAGUmJgoSaqsrAxYXllZ6V93NZfLpaioqIABAOj8ghpAKSkpSkxMVGFhoX+Zz+fT/v37lZ6eHsxNAQA6OMdXwX311VcqKSnxPy4rK9OhQ4cUHR2tAQMGaPHixXrppZd05513KiUlRc8//7w8Ho+mT58ezL4BAB2c4wA6cOCAHnjgAf/jvLw8SVJOTo4KCgq0ZMkSVVdX6+mnn1ZVVZXGjx+vrVu3qkePHsHrGgDQ4XEzUgBB8Y1vfMNxzZ///OcQdBI83Iz05nAzUgBAu0QAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVjv8cAwA0595777XdAjoYzoAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwApuRgogKJ555hnbLaCD4QwIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKzgZqTAFcaPH++4ZsiQIY5rGhoaHNcUFBQ4rmmt4cOHO66JiYkJQSfB8cc//rFVdRcuXAhyJ7gSZ0AAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAU3I+1kevXq5bgmKiqqVduaPn2645qzZ886rvn+97/vuKa1Bg8e7LjG4/E4rmlsbHRc893vftdxTWv179+/TWpa4+jRo45rZs2a1apt1dTUtKoON4YzIACAFQQQAMAKxwG0e/duPfzww/J4PAoLC9PmzZsD1s+ZM0dhYWEBY8qUKcHqFwDQSTgOoOrqao0aNUqrV69ucc6UKVN05swZ/3jnnXduqkkAQOfj+CKE7OxsZWdnX3OOy+VSYmJiq5sCAHR+IfkMqKioSPHx8RoyZIjmz5+vc+fOtTi3rq5OPp8vYAAAOr+gB9CUKVP029/+VoWFhXr55Ze1a9cuZWdnq6Ghodn5+fn5crvd/tFWl3ICAOwK+veArrzefsSIERo5cqQGDRqkoqIiTZo0qcn8pUuXKi8vz//Y5/MRQgBwCwj5ZdgDBw5UbGysSkpKml3vcrkUFRUVMAAAnV/IA+izzz7TuXPnlJSUFOpNAQA6EMdvwX311VcBZzNlZWU6dOiQoqOjFR0drZUrV+rRRx9VYmKiSktLtWTJEt1xxx3KysoKauMAgI7NcQAdOHBADzzwgP/x5c9vcnJytGbNGh0+fFj/+q//qqqqKnk8Hk2ePFkvvviiXC5X8LoGAHR4YcYYY7uJK/l8PrndbtttBN03vvENxzVTp051XJOenu64pjU3FQVsOXnypOOaNWvWtGpbr732muOaurq6Vm2rM/J6vdf8XJ97wQEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAK7obdRpYsWeK4Jj8/PwSd2FVbW+u45n/+538c1/Tq1ctxjSQlJye3qg6d07p16xzXLFq0yHGN1+t1XNMRcDdsAEC7RAABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAAruBlpG2lsbHRc087+0zRRVFTkuGb9+vWOa37zm984rrn99tsd10jShg0bHNekpqa2altt4fz5862qe/nll4PcSfMefPBBxzUTJkwIQSfBs2XLFsc1M2fODEEn9nEzUgBAu0QAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAK7gZaRtpzW5uzQ1M25LX63VcU1VVFfxGgigmJsZxTe/evUPQSVOVlZWOa+bMmdOqbf3Hf/xHq+qc6tu3r+Oaf/mXf3FcM2bMGMc1kpSYmNiqOqe6du3aJttpa9yMFADQLhFAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADAim62G7hVrF271nFNTk5OCDoJntbcNLYz3mj20KFDjmt+/etfO645duyY45qdO3c6rmlLX375peOaGTNmOK7JyMhwXCNJ//Zv/+a4ZsOGDa3a1q2IMyAAgBUEEADACkcBlJ+fr3vvvVeRkZGKj4/X9OnTdfz48YA5tbW1ys3NVUxMjHr37q1HH320VX/HBADQuTkKoF27dik3N1f79u3Ttm3bdOHCBU2ePFnV1dX+Oc8++6zef/99bdy4Ubt27dLp06c1c+bMoDcOAOjYHF2EsHXr1oDHBQUFio+PV3FxsTIyMuT1evWb3/xG69ev1ze/+U1Jlz58v+uuu7Rv3z6NHTs2eJ0DADq0m/oM6PKfZI6OjpYkFRcX68KFC8rMzPTPGTp0qAYMGKC9e/c2+xx1dXXy+XwBAwDQ+bU6gBobG7V48WKNGzdOw4cPlyRVVFQoPDxcffr0CZibkJCgioqKZp8nPz9fbrfbP/r379/algAAHUirAyg3N1dHjhzRu+++e1MNLF26VF6v1z/Ky8tv6vkAAB1Dq76IumDBAn3wwQfavXu3+vXr51+emJio+vp6VVVVBZwFVVZWKjExsdnncrlccrlcrWkDANCBOToDMsZowYIF2rRpk3bs2KGUlJSA9ampqerevbsKCwv9y44fP65Tp04pPT09OB0DADoFR2dAubm5Wr9+vbZs2aLIyEj/5zput1sRERFyu9363ve+p7y8PEVHRysqKkoLFy5Ueno6V8ABAAI4CqA1a9ZIkiZOnBiwfO3atZozZ44k6Wc/+5m6dOmiRx99VHV1dcrKytIbb7wRlGYBAJ1HmDHG2G7iSj6fr1PesDI8PNxxTWxsrOOat956y3FNZ5Sbm9uqustfLXDiwoULjmtqamoc16DtRUVFOa6pra11XFNfX++4piPwer3X3IfcCw4AYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWcDdsAEBIcDdsAEC7RAABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBY4SiA8vPzde+99yoyMlLx8fGaPn26jh8/HjBn4sSJCgsLCxjz5s0LatMAgI7PUQDt2rVLubm52rdvn7Zt26YLFy5o8uTJqq6uDpj31FNP6cyZM/7xyiuvBLVpAEDH183J5K1btwY8LigoUHx8vIqLi5WRkeFf3rNnTyUmJganQwBAp3RTnwF5vV5JUnR0dMDyt99+W7GxsRo+fLiWLl2qmpqaFp+jrq5OPp8vYAAAbgGmlRoaGsy0adPMuHHjApa/9dZbZuvWrebw4cPmd7/7nbntttvMjBkzWnye5cuXG0kMBoPB6GTD6/VeM0daHUDz5s0zycnJpry8/JrzCgsLjSRTUlLS7Pra2lrj9Xr9o7y83PpOYzAYDMbNj+sFkKPPgC5bsGCBPvjgA+3evVv9+vW75ty0tDRJUklJiQYNGtRkvcvlksvlak0bAIAOzFEAGWO0cOFCbdq0SUVFRUpJSbluzaFDhyRJSUlJrWoQANA5OQqg3NxcrV+/Xlu2bFFkZKQqKiokSW63WxERESotLdX69es1depUxcTE6PDhw3r22WeVkZGhkSNHhuQFAAA6KCef+6iF9/nWrl1rjDHm1KlTJiMjw0RHRxuXy2XuuOMO84Mf/OC67wNeyev1Wn/fksFgMBg3P673uz/s/wdLu+Hz+eR2u223AQC4SV6vV1FRUS2u515wAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAAr2l0AGWNstwAACILr/T5vdwF0/vx52y0AAILger/Pw0w7O+VobGzU6dOnFRkZqbCwsIB1Pp9P/fv3V3l5uaKioix1aB/74RL2wyXsh0vYD5e0h/1gjNH58+fl8XjUpUvL5znd2rCnG9KlSxf169fvmnOioqJu6QPsMvbDJeyHS9gPl7AfLrG9H9xu93XntLu34AAAtwYCCABgRYcKIJfLpeXLl8vlctluxSr2wyXsh0vYD5ewHy7pSPuh3V2EAAC4NXSoMyAAQOdBAAEArCCAAABWEEAAACsIIACAFR0mgFavXq3bb79dPXr0UFpamv70pz/ZbqnNrVixQmFhYQFj6NChttsKud27d+vhhx+Wx+NRWFiYNm/eHLDeGKNly5YpKSlJERERyszM1IkTJ+w0G0LX2w9z5sxpcnxMmTLFTrMhkp+fr3vvvVeRkZGKj4/X9OnTdfz48YA5tbW1ys3NVUxMjHr37q1HH31UlZWVljoOjRvZDxMnTmxyPMybN89Sx83rEAH03nvvKS8vT8uXL9cnn3yiUaNGKSsrS2fPnrXdWpsbNmyYzpw54x8ff/yx7ZZCrrq6WqNGjdLq1aubXf/KK6/oF7/4hd58803t379fvXr1UlZWlmpra9u409C63n6QpClTpgQcH++8804bdhh6u3btUm5urvbt26dt27bpwoULmjx5sqqrq/1znn32Wb3//vvauHGjdu3apdOnT2vmzJkWuw6+G9kPkvTUU08FHA+vvPKKpY5bYDqAMWPGmNzcXP/jhoYG4/F4TH5+vsWu2t7y5cvNqFGjbLdhlSSzadMm/+PGxkaTmJhofvKTn/iXVVVVGZfLZd555x0LHbaNq/eDMcbk5OSYRx55xEo/tpw9e9ZIMrt27TLGXPpv3717d7Nx40b/nE8//dRIMnv37rXVZshdvR+MMWbChAlm0aJF9pq6Ae3+DKi+vl7FxcXKzMz0L+vSpYsyMzO1d+9ei53ZceLECXk8Hg0cOFCPP/64Tp06Zbslq8rKylRRURFwfLjdbqWlpd2Sx0dRUZHi4+M1ZMgQzZ8/X+fOnbPdUkh5vV5JUnR0tCSpuLhYFy5cCDgehg4dqgEDBnTq4+Hq/XDZ22+/rdjYWA0fPlxLly5VTU2NjfZa1O7uhn21L774Qg0NDUpISAhYnpCQoGPHjlnqyo60tDQVFBRoyJAhOnPmjFauXKn7779fR44cUWRkpO32rKioqJCkZo+Py+tuFVOmTNHMmTOVkpKi0tJS/ehHP1J2drb27t2rrl272m4v6BobG7V48WKNGzdOw4cPl3TpeAgPD1efPn0C5nbm46G5/SBJ3/nOd5ScnCyPx6PDhw/rhz/8oY4fP67f//73FrsN1O4DCP8nOzvb//PIkSOVlpam5ORkbdiwQd/73vcsdob2YNasWf6fR4wYoZEjR2rQoEEqKirSpEmTLHYWGrm5uTpy5Mgt8TnotbS0H55++mn/zyNGjFBSUpImTZqk0tJSDRo0qK3bbFa7fwsuNjZWXbt2bXIVS2VlpRITEy111T706dNHgwcPVklJie1WrLl8DHB8NDVw4EDFxsZ2yuNjwYIF+uCDD7Rz586Avx+WmJio+vp6VVVVBczvrMdDS/uhOWlpaZLUro6Hdh9A4eHhSk1NVWFhoX9ZY2OjCgsLlZ6ebrEz+7766iuVlpYqKSnJdivWpKSkKDExMeD48Pl82r9//y1/fHz22Wc6d+5cpzo+jDFasGCBNm3apB07diglJSVgfWpqqrp37x5wPBw/flynTp3qVMfD9fZDcw4dOiRJ7et4sH0VxI149913jcvlMgUFBea///u/zdNPP2369OljKioqbLfWpv7hH/7BFBUVmbKyMrNnzx6TmZlpYmNjzdmzZ223FlLnz583Bw8eNAcPHjSSzKuvvmoOHjxo/vrXvxpjjPmnf/on06dPH7NlyxZz+PBh88gjj5iUlBTz9ddfW+48uK61H86fP2+ee+45s3fvXlNWVma2b99u7r77bnPnnXea2tpa260Hzfz5843b7TZFRUXmzJkz/lFTU+OfM2/ePDNgwACzY8cOc+DAAZOenm7S09Mtdh1819sPJSUl5oUXXjAHDhwwZWVlZsuWLWbgwIEmIyPDcueBOkQAGWPMa6+9ZgYMGGDCw8PNmDFjzL59+2y31OYee+wxk5SUZMLDw81tt91mHnvsMVNSUmK7rZDbuXOnkdRk5OTkGGMuXYr9/PPPm4SEBONyucykSZPM8ePH7TYdAtfaDzU1NWby5MkmLi7OdO/e3SQnJ5unnnqq0/0jrbnXL8msXbvWP+frr7823//+903fvn1Nz549zYwZM8yZM2fsNR0C19sPp06dMhkZGSY6Otq4XC5zxx13mB/84AfG6/Xabfwq/D0gAIAV7f4zIABA50QAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFb8P7Oal0GEmzuQAAAAAElFTkSuQmCC\n"},"metadata":{}}],"execution_count":38}]}