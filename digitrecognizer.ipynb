{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3004,"databundleVersionId":861823,"sourceType":"competition"}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-15T07:21:25.058141Z","iopub.execute_input":"2026-02-15T07:21:25.058365Z","iopub.status.idle":"2026-02-15T07:21:26.196920Z","shell.execute_reply.started":"2026-02-15T07:21:25.058343Z","shell.execute_reply":"2026-02-15T07:21:26.196326Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/digit-recognizer/sample_submission.csv\n/kaggle/input/digit-recognizer/train.csv\n/kaggle/input/digit-recognizer/test.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nimport pandas as pd\n\n# class DigitRecognizerDataset(Dataset):\n#     def __init__(self, dataframe, is_test=False):\n#         self.is_test = is_test\n        \n#         if not self.is_test:\n#             # Train set: First column is label, rest are pixels\n#             self.labels = torch.tensor(dataframe.iloc[:, 0].values, dtype=torch.long)\n#             data = dataframe.iloc[:, 1:].values\n#         else:\n#             # Test set: All columns are pixels, no labels provided\n#             self.labels = None \n#             data = dataframe.values\n            \n#         # Reshape the data to (Batch, Channel, Height, Width)\n#         self.features = torch.tensor(data, dtype=torch.float32).view(-1, 1, 28, 28)\n\n#     def __len__(self):\n#         return len(self.features)\n\n#     def __getitem__(self, idx):\n#         if self.is_test:\n#             return self.features[idx]\n#         return self.features[idx], self.labels[idx]\n\nclass DigitRecognizerDataset(Dataset):\n    def __init__(self, dataframe, is_test=False, transform=None):\n        self.is_test = is_test\n        self.transform = transform\n        \n        if not self.is_test:\n            self.labels = torch.tensor(dataframe.iloc[:, 0].values, dtype=torch.long)\n            data = dataframe.iloc[:, 1:].values\n        else:\n            self.labels = None \n            data = dataframe.values\n            \n        # Features are reshaped to (C, H, W)\n        self.features = torch.tensor(data, dtype=torch.float32).view(-1, 1, 28, 28)\n\n    def __len__(self):\n        return len(self.features)\n\n    def __getitem__(self, idx):\n        image = self.features[idx]\n        \n        # Normalize to [0, 1] range\n        image = image / 255.0\n        \n        # Apply augmentation if provided\n        if self.transform:\n            image = self.transform(image)\n            \n        if self.is_test:\n            return image\n        return image, self.labels[idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T07:21:26.198443Z","iopub.execute_input":"2026-02-15T07:21:26.198757Z","iopub.status.idle":"2026-02-15T07:21:33.641722Z","shell.execute_reply.started":"2026-02-15T07:21:26.198733Z","shell.execute_reply":"2026-02-15T07:21:33.640714Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Load datasets\ntrain_set_filepath = '/kaggle/input/digit-recognizer/train.csv'\ntest_set_filepath = '/kaggle/input/digit-recognizer/test.csv'\nbase_train_df = pd.read_csv(train_set_filepath)\nbase_test_df = pd.read_csv(test_set_filepath)\n\n# Only the train set has labels so we need to split that into our real train and test sets\ntrain_df, val_df = train_test_split(base_train_df, test_size=0.2, random_state=42)\n\ntrain_transforms = transforms.Compose([\n    transforms.RandomRotation(10), # Rotate up to 10 degrees\n    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)), # Shift and Zoom\n])\n\n# Convert to torch datasets\n# train_set = DigitRecognizerDataset(train_df, is_test=False)\ntrain_set = DigitRecognizerDataset(train_df, is_test=False, transform=train_transforms)\nval_set = DigitRecognizerDataset(val_df, is_test=False)\ntest_set = DigitRecognizerDataset(base_test_df, is_test=True)\n\ntrain_loader = DataLoader(train_set, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_set, batch_size=32, shuffle=False)\ntest_loader = DataLoader(test_set, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T07:21:33.642659Z","iopub.execute_input":"2026-02-15T07:21:33.643130Z","iopub.status.idle":"2026-02-15T07:21:38.660669Z","shell.execute_reply.started":"2026-02-15T07:21:33.643095Z","shell.execute_reply":"2026-02-15T07:21:38.660013Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\n\n# class CNN(nn.Module):\n#     def __init__(self):\n#         super().__init__()\n#         self.conv1 = nn.Conv2d(1, 6, 5)\n#         self.pool = nn.MaxPool2d(2, 2)\n#         self.conv2 = nn.Conv2d(6, 16, 5)\n#         self.fc1 = nn.Linear(16 * 4 * 4, 120)\n#         self.fc2 = nn.Linear(120, 84)\n#         self.fc3 = nn.Linear(84, 10)\n\n#     def forward(self, x):\n#         x = self.pool(F.relu(self.conv1(x)))\n#         x = self.pool(F.relu(self.conv2(x)))\n#         x = torch.flatten(x, 1) # flatten all dimensions except batch\n#         x = F.relu(self.fc1(x))\n#         x = F.relu(self.fc2(x))\n#         x = self.fc3(x)\n#         return x\n\nclass CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        \n        # Block 1: Input 1x28x28 -> Output 32x14x14\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n        self.bn1 = nn.BatchNorm2d(32)\n        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n        self.bn2 = nn.BatchNorm2d(32)\n        self.pool1 = nn.MaxPool2d(2)\n        self.drop1 = nn.Dropout2d(0.25)\n\n        # Block 2: Input 32x14x14 -> Output 64x7x7\n        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.bn3 = nn.BatchNorm2d(64)\n        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n        self.bn4 = nn.BatchNorm2d(64)\n        self.pool2 = nn.MaxPool2d(2)\n        self.drop2 = nn.Dropout2d(0.25)\n\n        # Fully Connected Classifier\n        self.fc1 = nn.Linear(64 * 7 * 7, 256)\n        self.bn5 = nn.BatchNorm1d(256)\n        self.drop3 = nn.Dropout(0.5)\n        self.fc2 = nn.Linear(256, 10)\n\n    def forward(self, x):\n        # Block 1\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = self.pool1(x)\n        x = self.drop1(x)\n\n        # Block 2\n        x = F.relu(self.bn3(self.conv3(x)))\n        x = F.relu(self.bn4(self.conv4(x)))\n        x = self.pool2(x)\n        x = self.drop2(x)\n\n        # Flatten and Classify\n        x = torch.flatten(x, 1)\n        x = F.relu(self.bn5(self.fc1(x)))\n        x = self.drop3(x)\n        x = self.fc2(x)\n        return x\n\n# cnn = CNN()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T07:21:38.661816Z","iopub.execute_input":"2026-02-15T07:21:38.662077Z","iopub.status.idle":"2026-02-15T07:21:38.671027Z","shell.execute_reply.started":"2026-02-15T07:21:38.662053Z","shell.execute_reply":"2026-02-15T07:21:38.670265Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import torch.optim as optim\n\ncriterion = nn.CrossEntropyLoss()\n\n# optimizer = optim.SGD(cnn.parameters(), lr=0.001, momentum=0.9)\n# optimizer = optim.Adam(cnn.parameters(), lr=0.001)\n\n# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2)\n# EPOCHS = 30\n# scheduler = optim.lr_scheduler.OneCycleLR(\n#     optimizer, \n#     max_lr=0.01, # The peak learning rate\n#     steps_per_epoch=len(train_loader), \n#     epochs=EPOCHS,\n#     pct_start=0.3, # Spend 30% of the time warming up\n#     anneal_strategy='cos' # Use cosine annealing for the cooldown\n# )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T07:21:38.672036Z","iopub.execute_input":"2026-02-15T07:21:38.672542Z","iopub.status.idle":"2026-02-15T07:21:38.805705Z","shell.execute_reply.started":"2026-02-15T07:21:38.672505Z","shell.execute_reply":"2026-02-15T07:21:38.805024Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\nNUM_MODELS = 5 # Number of models in ensemble\nmodels = []\noptimizers = []\nschedulers = []\n\nfor i in range(NUM_MODELS):\n    # Set a unique seed for each model instance\n    torch.manual_seed(42 + i) \n    \n    model = CNN().to(device) \n    models.append(model)\n    \n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    optimizers.append(optimizer)\n    \n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2)\n    schedulers.append(scheduler)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T07:21:38.806633Z","iopub.execute_input":"2026-02-15T07:21:38.806942Z","iopub.status.idle":"2026-02-15T07:21:39.397611Z","shell.execute_reply.started":"2026-02-15T07:21:38.806906Z","shell.execute_reply":"2026-02-15T07:21:39.396864Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## Train & Test","metadata":{}},{"cell_type":"code","source":"# Test\ndef test_model(model):\n    model.eval() # Set model to evaluation mode\n    correct = 0\n    total = 0\n    val_loss = 0.0\n    with torch.no_grad():\n        for data in val_loader:\n            images, labels = data\n            images = images.to(device)\n            labels = labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels) # Calculate loss\n            val_loss += loss.item()\n            \n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    \n    avg_loss = val_loss / len(val_loader)\n    print(f'Accuracy: {100 * correct / total:.2f}% | Val Loss: {avg_loss:.4f}')\n    return avg_loss # Return this for the scheduler","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T07:21:39.399372Z","iopub.execute_input":"2026-02-15T07:21:39.399606Z","iopub.status.idle":"2026-02-15T07:21:39.404709Z","shell.execute_reply.started":"2026-02-15T07:21:39.399584Z","shell.execute_reply":"2026-02-15T07:21:39.404114Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Train\nEPOCHS = 30\nfor m_idx, cnn in enumerate(models):\n    print(f\"Training Model {m_idx + 1}/{len(models)}...\")\n    optimizer = optimizers[m_idx]\n    scheduler = schedulers[m_idx]\n    \n    for epoch in range(EPOCHS):\n        cnn.train() # Set model back to training mode\n        running_loss = 0.0\n        for i, data in enumerate(train_loader, 0):\n            inputs, labels = data\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            optimizer.zero_grad()\n            outputs = cnn(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            # scheduler.step() # needed if using OneCycleLR\n    \n            running_loss += loss.item()\n            if i % 100 == 99:\n                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 100:.3f}')\n                running_loss = 0.0\n    \n        # Run validation and get the loss\n        current_val_loss = test_model(cnn)\n        \n        # Step the scheduler based on the validation loss\n        scheduler.step(current_val_loss)\n        \n        # Optional: Print current learning rate to see it in action\n        current_lr = optimizer.param_groups[0]['lr']\n        print(f'End of Epoch {epoch + 1} - Learning Rate: {current_lr}')\n\n    print(f'Finished Training Model {m_idx + 1}')\n\nprint('Finished Training')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T07:21:39.405559Z","iopub.execute_input":"2026-02-15T07:21:39.405858Z","execution_failed":"2026-02-15T08:22:42.685Z"}},"outputs":[{"name":"stdout","text":"Training Model 1/5...\n[1,   100] loss: 1.182\n[1,   200] loss: 0.526\n[1,   300] loss: 0.402\n[1,   400] loss: 0.308\n[1,   500] loss: 0.277\n[1,   600] loss: 0.228\n[1,   700] loss: 0.231\n[1,   800] loss: 0.212\n[1,   900] loss: 0.195\n[1,  1000] loss: 0.211\nAccuracy: 98.50% | Val Loss: 0.0470\nEnd of Epoch 1 - Learning Rate: 0.001\n[2,   100] loss: 0.192\n[2,   200] loss: 0.171\n[2,   300] loss: 0.148\n[2,   400] loss: 0.160\n[2,   500] loss: 0.162\n[2,   600] loss: 0.163\n[2,   700] loss: 0.158\n[2,   800] loss: 0.136\n[2,   900] loss: 0.124\n[2,  1000] loss: 0.131\nAccuracy: 98.87% | Val Loss: 0.0353\nEnd of Epoch 2 - Learning Rate: 0.001\n[3,   100] loss: 0.137\n[3,   200] loss: 0.115\n[3,   300] loss: 0.135\n[3,   400] loss: 0.138\n[3,   500] loss: 0.118\n[3,   600] loss: 0.129\n[3,   700] loss: 0.127\n[3,   800] loss: 0.109\n[3,   900] loss: 0.117\n[3,  1000] loss: 0.126\nAccuracy: 98.99% | Val Loss: 0.0282\nEnd of Epoch 3 - Learning Rate: 0.001\n[4,   100] loss: 0.108\n[4,   200] loss: 0.110\n[4,   300] loss: 0.121\n[4,   400] loss: 0.115\n[4,   500] loss: 0.113\n[4,   600] loss: 0.121\n[4,   700] loss: 0.106\n[4,   800] loss: 0.102\n[4,   900] loss: 0.108\n[4,  1000] loss: 0.098\nAccuracy: 99.24% | Val Loss: 0.0223\nEnd of Epoch 4 - Learning Rate: 0.001\n[5,   100] loss: 0.108\n[5,   200] loss: 0.105\n[5,   300] loss: 0.099\n[5,   400] loss: 0.103\n[5,   500] loss: 0.100\n[5,   600] loss: 0.095\n[5,   700] loss: 0.095\n[5,   800] loss: 0.093\n[5,   900] loss: 0.098\n[5,  1000] loss: 0.089\nAccuracy: 99.29% | Val Loss: 0.0218\nEnd of Epoch 5 - Learning Rate: 0.001\n[6,   100] loss: 0.084\n[6,   200] loss: 0.088\n[6,   300] loss: 0.072\n[6,   400] loss: 0.093\n[6,   500] loss: 0.091\n[6,   600] loss: 0.091\n[6,   700] loss: 0.095\n[6,   800] loss: 0.084\n[6,   900] loss: 0.079\n[6,  1000] loss: 0.075\nAccuracy: 99.21% | Val Loss: 0.0223\nEnd of Epoch 6 - Learning Rate: 0.001\n[7,   100] loss: 0.085\n[7,   200] loss: 0.112\n[7,   300] loss: 0.076\n[7,   400] loss: 0.074\n[7,   500] loss: 0.086\n[7,   600] loss: 0.070\n[7,   700] loss: 0.097\n[7,   800] loss: 0.097\n[7,   900] loss: 0.087\n[7,  1000] loss: 0.088\nAccuracy: 99.32% | Val Loss: 0.0181\nEnd of Epoch 7 - Learning Rate: 0.001\n[8,   100] loss: 0.080\n[8,   200] loss: 0.085\n[8,   300] loss: 0.077\n[8,   400] loss: 0.089\n[8,   500] loss: 0.082\n[8,   600] loss: 0.075\n[8,   700] loss: 0.086\n[8,   800] loss: 0.080\n[8,   900] loss: 0.070\n[8,  1000] loss: 0.083\nAccuracy: 99.29% | Val Loss: 0.0203\nEnd of Epoch 8 - Learning Rate: 0.001\n[9,   100] loss: 0.081\n[9,   200] loss: 0.086\n[9,   300] loss: 0.080\n[9,   400] loss: 0.067\n[9,   500] loss: 0.077\n[9,   600] loss: 0.092\n[9,   700] loss: 0.073\n[9,   800] loss: 0.080\n[9,   900] loss: 0.073\n[9,  1000] loss: 0.063\nAccuracy: 99.40% | Val Loss: 0.0175\nEnd of Epoch 9 - Learning Rate: 0.001\n[10,   100] loss: 0.086\n[10,   200] loss: 0.082\n[10,   300] loss: 0.070\n[10,   400] loss: 0.093\n[10,   500] loss: 0.066\n[10,   600] loss: 0.072\n[10,   700] loss: 0.075\n[10,   800] loss: 0.079\n[10,   900] loss: 0.079\n[10,  1000] loss: 0.059\nAccuracy: 99.43% | Val Loss: 0.0162\nEnd of Epoch 10 - Learning Rate: 0.001\n[11,   100] loss: 0.063\n[11,   200] loss: 0.069\n[11,   300] loss: 0.065\n[11,   400] loss: 0.070\n[11,   500] loss: 0.073\n[11,   600] loss: 0.091\n[11,   700] loss: 0.073\n[11,   800] loss: 0.068\n[11,   900] loss: 0.051\n[11,  1000] loss: 0.073\nAccuracy: 99.27% | Val Loss: 0.0213\nEnd of Epoch 11 - Learning Rate: 0.001\n[12,   100] loss: 0.058\n[12,   200] loss: 0.069\n[12,   300] loss: 0.060\n[12,   400] loss: 0.077\n[12,   500] loss: 0.057\n[12,   600] loss: 0.079\n[12,   700] loss: 0.083\n[12,   800] loss: 0.073\n[12,   900] loss: 0.075\n[12,  1000] loss: 0.068\nAccuracy: 99.46% | Val Loss: 0.0172\nEnd of Epoch 12 - Learning Rate: 0.001\n[13,   100] loss: 0.057\n[13,   200] loss: 0.071\n[13,   300] loss: 0.079\n[13,   400] loss: 0.077\n[13,   500] loss: 0.065\n[13,   600] loss: 0.068\n[13,   700] loss: 0.061\n[13,   800] loss: 0.059\n[13,   900] loss: 0.071\n[13,  1000] loss: 0.079\nAccuracy: 99.38% | Val Loss: 0.0179\nEnd of Epoch 13 - Learning Rate: 0.0001\n[14,   100] loss: 0.060\n[14,   200] loss: 0.063\n[14,   300] loss: 0.052\n[14,   400] loss: 0.062\n[14,   500] loss: 0.053\n[14,   600] loss: 0.039\n[14,   700] loss: 0.054\n[14,   800] loss: 0.062\n[14,   900] loss: 0.050\n[14,  1000] loss: 0.056\nAccuracy: 99.48% | Val Loss: 0.0140\nEnd of Epoch 14 - Learning Rate: 0.0001\n[15,   100] loss: 0.044\n[15,   200] loss: 0.052\n[15,   300] loss: 0.055\n[15,   400] loss: 0.044\n[15,   500] loss: 0.049\n[15,   600] loss: 0.047\n[15,   700] loss: 0.036\n[15,   800] loss: 0.047\n[15,   900] loss: 0.052\n[15,  1000] loss: 0.079\nAccuracy: 99.50% | Val Loss: 0.0133\nEnd of Epoch 15 - Learning Rate: 0.0001\n[16,   100] loss: 0.042\n[16,   200] loss: 0.051\n[16,   300] loss: 0.047\n[16,   400] loss: 0.056\n[16,   500] loss: 0.040\n[16,   600] loss: 0.043\n[16,   700] loss: 0.057\n[16,   800] loss: 0.037\n[16,   900] loss: 0.044\n[16,  1000] loss: 0.058\nAccuracy: 99.56% | Val Loss: 0.0133\nEnd of Epoch 16 - Learning Rate: 0.0001\n[17,   100] loss: 0.040\n[17,   200] loss: 0.044\n[17,   300] loss: 0.040\n[17,   400] loss: 0.044\n[17,   500] loss: 0.045\n[17,   600] loss: 0.034\n[17,   700] loss: 0.048\n[17,   800] loss: 0.038\n[17,   900] loss: 0.053\n[17,  1000] loss: 0.061\nAccuracy: 99.54% | Val Loss: 0.0132\nEnd of Epoch 17 - Learning Rate: 0.0001\n[18,   100] loss: 0.044\n[18,   200] loss: 0.041\n[18,   300] loss: 0.029\n[18,   400] loss: 0.050\n[18,   500] loss: 0.049\n[18,   600] loss: 0.039\n[18,   700] loss: 0.046\n[18,   800] loss: 0.047\n[18,   900] loss: 0.044\n[18,  1000] loss: 0.049\nAccuracy: 99.51% | Val Loss: 0.0129\nEnd of Epoch 18 - Learning Rate: 0.0001\n[19,   100] loss: 0.041\n[19,   200] loss: 0.057\n[19,   300] loss: 0.042\n[19,   400] loss: 0.043\n[19,   500] loss: 0.040\n[19,   600] loss: 0.047\n[19,   700] loss: 0.036\n[19,   800] loss: 0.045\n[19,   900] loss: 0.030\n[19,  1000] loss: 0.040\nAccuracy: 99.56% | Val Loss: 0.0136\nEnd of Epoch 19 - Learning Rate: 0.0001\n[20,   100] loss: 0.045\n[20,   200] loss: 0.058\n[20,   300] loss: 0.047\n[20,   400] loss: 0.041\n[20,   500] loss: 0.046\n[20,   600] loss: 0.028\n[20,   700] loss: 0.033\n[20,   800] loss: 0.042\n[20,   900] loss: 0.041\n[20,  1000] loss: 0.037\nAccuracy: 99.60% | Val Loss: 0.0129\nEnd of Epoch 20 - Learning Rate: 0.0001\n[21,   100] loss: 0.042\n[21,   200] loss: 0.051\n[21,   300] loss: 0.039\n[21,   400] loss: 0.047\n[21,   500] loss: 0.037\n[21,   600] loss: 0.043\n[21,   700] loss: 0.047\n[21,   800] loss: 0.036\n[21,   900] loss: 0.034\n[21,  1000] loss: 0.041\nAccuracy: 99.56% | Val Loss: 0.0130\nEnd of Epoch 21 - Learning Rate: 1e-05\n[22,   100] loss: 0.040\n[22,   200] loss: 0.049\n[22,   300] loss: 0.042\n[22,   400] loss: 0.046\n[22,   500] loss: 0.033\n[22,   600] loss: 0.055\n[22,   700] loss: 0.041\n[22,   800] loss: 0.037\n[22,   900] loss: 0.041\n[22,  1000] loss: 0.054\nAccuracy: 99.56% | Val Loss: 0.0133\nEnd of Epoch 22 - Learning Rate: 1e-05\n[23,   100] loss: 0.053\n[23,   200] loss: 0.038\n[23,   300] loss: 0.060\n[23,   400] loss: 0.047\n[23,   500] loss: 0.039\n[23,   600] loss: 0.044\n[23,   700] loss: 0.042\n[23,   800] loss: 0.038\n[23,   900] loss: 0.035\n[23,  1000] loss: 0.043\nAccuracy: 99.55% | Val Loss: 0.0133\nEnd of Epoch 23 - Learning Rate: 1e-05\n[24,   100] loss: 0.039\n[24,   200] loss: 0.048\n[24,   300] loss: 0.037\n[24,   400] loss: 0.043\n[24,   500] loss: 0.035\n[24,   600] loss: 0.036\n[24,   700] loss: 0.040\n[24,   800] loss: 0.045\n[24,   900] loss: 0.028\n[24,  1000] loss: 0.047\nAccuracy: 99.56% | Val Loss: 0.0137\nEnd of Epoch 24 - Learning Rate: 1.0000000000000002e-06\n[25,   100] loss: 0.035\n[25,   200] loss: 0.036\n[25,   300] loss: 0.030\n[25,   400] loss: 0.039\n[25,   500] loss: 0.031\n[25,   600] loss: 0.028\n[25,   700] loss: 0.047\n[25,   800] loss: 0.039\n[25,   900] loss: 0.045\n[25,  1000] loss: 0.051\nAccuracy: 99.55% | Val Loss: 0.0133\nEnd of Epoch 25 - Learning Rate: 1.0000000000000002e-06\n[26,   100] loss: 0.047\n[26,   200] loss: 0.038\n[26,   300] loss: 0.031\n[26,   400] loss: 0.048\n[26,   500] loss: 0.046\n[26,   600] loss: 0.047\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"test_model()","metadata":{"trusted":true,"execution":{"execution_failed":"2026-02-15T08:22:42.685Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"# Submission\nsubmission_data = {'ImageId': [], 'Label': []}\n\n# Set all models to eval mode\nfor cnn in models:\n    cnn.eval()\n\nwith torch.no_grad():\n    idx = 1\n    for images in test_loader:\n        images = images.to(device)\n        \n        # Initialize an empty tensor to store accumulated predictions\n        # Shape: [batch_size, num_classes]\n        ensemble_logits = torch.zeros((images.size(0), 10)).to(device) \n        \n        for cnn in models:\n            outputs = cnn(images)\n            ensemble_logits += outputs # Summing the logits\n        \n        # Get the index of the max accumulated log-probability\n        _, predicted = torch.max(ensemble_logits, 1)\n\n        preds = predicted.cpu().numpy()\n\n        for p in preds:\n            submission_data['ImageId'].append(idx)\n            submission_data['Label'].append(p)\n            idx += 1\n\n# Save to csv\nsubmission_df = pd.DataFrame(submission_data)\nsubmission_df.to_csv('submission.csv', index=False)\nprint(\"Submission file saved!\")","metadata":{"trusted":true,"execution":{"execution_failed":"2026-02-15T08:22:42.685Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Verification","metadata":{}},{"cell_type":"code","source":"# 1. Check for missing values\nmissing_values = submission_df.isnull().sum().sum()\n\n# 2. Check for correct label range (0-9)\ninvalid_labels = submission_df[(submission_df['Label'] < 0) | (submission_df['Label'] > 9)]\n\n# 3. Final Verification Report\nprint(\"--- Submission Verification ---\")\nprint(f\"Total Rows: {len(submission_df)}\")\nprint(f\"Missing Values: {missing_values}\")\nprint(f\"Invalid Labels Found: {len(invalid_labels)}\")\nprint(f\"Column Names: {list(submission_df.columns)}\")\n\nif len(submission_df) == len(real_test_df) and missing_values == 0 and len(invalid_labels) == 0:\n    print(\"\\n✅ Verification Passed! Your file is ready for submission.\")\nelse:\n    print(\"\\n❌ Verification Failed. Please check the counts above.\")","metadata":{"trusted":true,"execution":{"execution_failed":"2026-02-15T08:22:42.685Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Get one batch from the test loader\nimages = next(iter(test_loader))\noutputs = cnn(images)\n_, predicted = torch.max(outputs, 1)\n\n# Plot the first image in the batch\nplt.imshow(images[0].reshape(28, 28), cmap='gray')\nplt.title(f'Predicted Label: {predicted[0].item()}')\nplt.show()","metadata":{"trusted":true,"execution":{"execution_failed":"2026-02-15T08:22:42.685Z"}},"outputs":[],"execution_count":null}]}