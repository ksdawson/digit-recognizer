{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-02-15T07:21:25.058365Z",
     "iopub.status.busy": "2026-02-15T07:21:25.058141Z",
     "iopub.status.idle": "2026-02-15T07:21:26.196920Z",
     "shell.execute_reply": "2026-02-15T07:21:26.196326Z",
     "shell.execute_reply.started": "2026-02-15T07:21:25.058343Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T07:21:26.198757Z",
     "iopub.status.busy": "2026-02-15T07:21:26.198443Z",
     "iopub.status.idle": "2026-02-15T07:21:33.641722Z",
     "shell.execute_reply": "2026-02-15T07:21:33.640714Z",
     "shell.execute_reply.started": "2026-02-15T07:21:26.198733Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DigitRecognizerDataset(Dataset):\n",
    "    def __init__(self, dataframe, is_test=False):\n",
    "        self.is_test = is_test\n",
    "        \n",
    "        if not self.is_test:\n",
    "            # Train set: First column is label, rest are pixels\n",
    "            self.labels = torch.tensor(dataframe.iloc[:, 0].values, dtype=torch.long)\n",
    "            data = dataframe.iloc[:, 1:].values\n",
    "        else:\n",
    "            # Test set: All columns are pixels, no labels provided\n",
    "            self.labels = None \n",
    "            data = dataframe.values\n",
    "            \n",
    "        # Reshape the data to (Batch, Channel, Height, Width)\n",
    "        self.features = torch.tensor(data, dtype=torch.float32).view(-1, 1, 28, 28)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.is_test:\n",
    "            return self.features[idx]\n",
    "        return self.features[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T07:21:33.643130Z",
     "iopub.status.busy": "2026-02-15T07:21:33.642659Z",
     "iopub.status.idle": "2026-02-15T07:21:38.660669Z",
     "shell.execute_reply": "2026-02-15T07:21:38.660013Z",
     "shell.execute_reply.started": "2026-02-15T07:21:33.643095Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_set_filepath = os.path.join(os.getcwd(), 'train.csv')\n",
    "test_set_filepath = os.path.join(os.getcwd(), 'test.csv')\n",
    "\n",
    "# Load datasets\n",
    "base_train_df = pd.read_csv(train_set_filepath)\n",
    "if os.path.exists(test_set_filepath):\n",
    "    base_test_df = pd.read_csv(test_set_filepath)\n",
    "else:\n",
    "    base_test_df = None\n",
    "\n",
    "# Only the train set has labels so we need to split that into our real train and test sets\n",
    "train_df, val_df = train_test_split(base_train_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to torch datasets\n",
    "train_set = DigitRecognizerDataset(train_df, is_test=False)\n",
    "val_set = DigitRecognizerDataset(val_df, is_test=False)\n",
    "if base_test_df:\n",
    "    test_set = DigitRecognizerDataset(base_test_df, is_test=True)\n",
    "else:\n",
    "    test_set = None\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=32, shuffle=False)\n",
    "if test_set:\n",
    "    test_loader = DataLoader(test_set, batch_size=32, shuffle=False)\n",
    "else:\n",
    "    test_loader = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T07:21:38.662077Z",
     "iopub.status.busy": "2026-02-15T07:21:38.661816Z",
     "iopub.status.idle": "2026-02-15T07:21:38.671027Z",
     "shell.execute_reply": "2026-02-15T07:21:38.670265Z",
     "shell.execute_reply.started": "2026-02-15T07:21:38.662053Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T07:21:38.672542Z",
     "iopub.status.busy": "2026-02-15T07:21:38.672036Z",
     "iopub.status.idle": "2026-02-15T07:21:38.805705Z",
     "shell.execute_reply": "2026-02-15T07:21:38.805024Z",
     "shell.execute_reply.started": "2026-02-15T07:21:38.672505Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device('mps')\n",
    "\n",
    "cnn = CNN().to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T07:21:39.399606Z",
     "iopub.status.busy": "2026-02-15T07:21:39.399372Z",
     "iopub.status.idle": "2026-02-15T07:21:39.404709Z",
     "shell.execute_reply": "2026-02-15T07:21:39.404114Z",
     "shell.execute_reply.started": "2026-02-15T07:21:39.399584Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Validation\n",
    "def validate_model(model):\n",
    "    model.eval() # Set model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in val_loader:\n",
    "            images, labels = data\n",
    "            images = images.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels) # Calculate loss\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    avg_loss = val_loss / len(val_loader)\n",
    "    print(f'Accuracy: {100 * correct / total:.2f}% | Val Loss: {avg_loss:.4f}')\n",
    "    return avg_loss # Return this for the scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2026-02-15T08:22:42.685Z",
     "iopub.execute_input": "2026-02-15T07:21:39.405858Z",
     "iopub.status.busy": "2026-02-15T07:21:39.405559Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    cnn.train() # Set model back to training mode\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 100:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "    # Run validation and get the loss\n",
    "    current_val_loss = validate_model(cnn)\n",
    "\n",
    "    # Step the scheduler based on the validation loss\n",
    "    scheduler.step(current_val_loss)\n",
    "    \n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f'End of Epoch {epoch + 1} - Learning Rate: {current_lr}')\n",
    "    \n",
    "    print(f'End of Epoch {epoch + 1}')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2026-02-15T08:22:42.685Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Submission\n",
    "submission_df = None\n",
    "if test_loader:\n",
    "    submission_data = {'ImageId': [], 'Label': []}\n",
    "\n",
    "    cnn.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        idx = 1\n",
    "        for images in test_loader:\n",
    "            images = images.to(DEVICE)\n",
    "            logits = cnn(images)\n",
    "            \n",
    "            # Get the index of the max accumulated log-probability\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "\n",
    "            preds = predicted.cpu().numpy()\n",
    "\n",
    "            for p in preds:\n",
    "                submission_data['ImageId'].append(idx)\n",
    "                submission_data['Label'].append(p)\n",
    "                idx += 1\n",
    "\n",
    "    # Save to csv\n",
    "    submission_df = pd.DataFrame(submission_data)\n",
    "    submission_df.to_csv('submission.csv', index=False)\n",
    "    print(\"Submission file saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2026-02-15T08:22:42.685Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if submission_df:\n",
    "    # 1. Check for missing values\n",
    "    missing_values = submission_df.isnull().sum().sum()\n",
    "\n",
    "    # 2. Check for correct label range (0-9)\n",
    "    invalid_labels = submission_df[(submission_df['Label'] < 0) | (submission_df['Label'] > 9)]\n",
    "\n",
    "    # 3. Final Verification Report\n",
    "    print(\"--- Submission Verification ---\")\n",
    "    print(f\"Total Rows: {len(submission_df)}\")\n",
    "    print(f\"Missing Values: {missing_values}\")\n",
    "    print(f\"Invalid Labels Found: {len(invalid_labels)}\")\n",
    "    print(f\"Column Names: {list(submission_df.columns)}\")\n",
    "\n",
    "    if len(submission_df) == len(real_test_df) and missing_values == 0 and len(invalid_labels) == 0:\n",
    "        print(\"\\n✅ Verification Passed! Your file is ready for submission.\")\n",
    "    else:\n",
    "        print(\"\\n❌ Verification Failed. Please check the counts above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2026-02-15T08:22:42.685Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if submission_df:    \n",
    "    # Get one batch from the test loader\n",
    "    images = next(iter(test_loader))\n",
    "    outputs = cnn(images)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    # Plot the first image in the batch\n",
    "    plt.imshow(images[0].reshape(28, 28), cmap='gray')\n",
    "    plt.title(f'Predicted Label: {predicted[0].item()}')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 861823,
     "sourceId": 3004,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31259,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
