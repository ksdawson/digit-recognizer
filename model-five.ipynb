{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3004,"databundleVersionId":861823,"sourceType":"competition"}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-16T02:26:31.592448Z","iopub.execute_input":"2026-02-16T02:26:31.593294Z","iopub.status.idle":"2026-02-16T02:26:31.599517Z","shell.execute_reply.started":"2026-02-16T02:26:31.593262Z","shell.execute_reply":"2026-02-16T02:26:31.598964Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Imports\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T02:26:31.605395Z","iopub.execute_input":"2026-02-16T02:26:31.605655Z","iopub.status.idle":"2026-02-16T02:26:31.613858Z","shell.execute_reply.started":"2026-02-16T02:26:31.605633Z","shell.execute_reply":"2026-02-16T02:26:31.613291Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"code","source":"class DigitRecognizerDataset(Dataset):\n    def __init__(self, dataframe, is_test=False, transform=None):\n        self.is_test = is_test\n        self.transform = transform\n        \n        if not self.is_test:\n            self.labels = torch.tensor(dataframe.iloc[:, 0].values, dtype=torch.long)\n            data = dataframe.iloc[:, 1:].values\n        else:\n            self.labels = None \n            data = dataframe.values\n            \n        # Features are reshaped to (C, H, W)\n        self.features = torch.tensor(data, dtype=torch.float32).view(-1, 1, 28, 28)\n\n    def __len__(self):\n        return len(self.features)\n\n    def __getitem__(self, idx):\n        image = self.features[idx]\n        \n        # Normalize to [0, 1] range\n        image = image / 255.0\n        \n        # Apply augmentation if provided\n        if self.transform:\n            image = self.transform(image)\n            \n        if self.is_test:\n            return image\n        return image, self.labels[idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T02:26:31.615472Z","iopub.execute_input":"2026-02-16T02:26:31.615753Z","iopub.status.idle":"2026-02-16T02:26:31.625561Z","shell.execute_reply.started":"2026-02-16T02:26:31.615722Z","shell.execute_reply":"2026-02-16T02:26:31.624939Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"KAGGLE = True\nif KAGGLE:\n    train_set_filepath = '/kaggle/input/digit-recognizer/train.csv'\n    test_set_filepath = '/kaggle/input/digit-recognizer/test.csv'\nelse:\n    train_set_filepath = os.path.join(os.getcwd(), 'train.csv')\n    test_set_filepath = os.path.join(os.getcwd(), 'test.csv')\n\n# Load datasets\nbase_train_df = pd.read_csv(train_set_filepath)\nif os.path.exists(test_set_filepath):\n    base_test_df = pd.read_csv(test_set_filepath)\nelse:\n    base_test_df = None\n\n# Only the train set has labels so we need to split that into our real train and test sets\ntrain_df, val_df = train_test_split(base_train_df, test_size=0.2, random_state=42)\n\ntrain_transforms = transforms.Compose([\n    transforms.RandomRotation(10), # Rotate up to 10 degrees\n    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)), # Shift and Zoom\n])\n\n# Convert to torch datasets\ntrain_set = DigitRecognizerDataset(train_df, is_test=False, transform=train_transforms)\nval_set = DigitRecognizerDataset(val_df, is_test=False)\nif base_test_df is not None:\n    test_set = DigitRecognizerDataset(base_test_df, is_test=True)\nelse:\n    test_set = None\n\n# Create data loaders\ntrain_loader = DataLoader(train_set, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_set, batch_size=32, shuffle=False)\nif test_set is not None:\n    test_loader = DataLoader(test_set, batch_size=32, shuffle=False)\nelse:\n    test_loader = None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T02:26:31.626385Z","iopub.execute_input":"2026-02-16T02:26:31.626750Z","iopub.status.idle":"2026-02-16T02:26:34.721943Z","shell.execute_reply.started":"2026-02-16T02:26:31.626728Z","shell.execute_reply":"2026-02-16T02:26:34.721327Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        \n        # Block 1: Input 1x28x28 -> Output 32x14x14\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n        self.bn1 = nn.BatchNorm2d(32)\n        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n        self.bn2 = nn.BatchNorm2d(32)\n        self.pool1 = nn.MaxPool2d(2)\n        self.drop1 = nn.Dropout2d(0.25)\n\n        # Block 2: Input 32x14x14 -> Output 64x7x7\n        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.bn3 = nn.BatchNorm2d(64)\n        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n        self.bn4 = nn.BatchNorm2d(64)\n        self.pool2 = nn.MaxPool2d(2)\n        self.drop2 = nn.Dropout2d(0.25)\n\n        # Fully Connected Classifier\n        self.fc1 = nn.Linear(64 * 7 * 7, 256)\n        self.bn5 = nn.BatchNorm1d(256)\n        self.drop3 = nn.Dropout(0.5)\n        self.fc2 = nn.Linear(256, 10)\n\n    def forward(self, x):\n        # Block 1\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = self.pool1(x)\n        x = self.drop1(x)\n\n        # Block 2\n        x = F.relu(self.bn3(self.conv3(x)))\n        x = F.relu(self.bn4(self.conv4(x)))\n        x = self.pool2(x)\n        x = self.drop2(x)\n\n        # Flatten and Classify\n        x = torch.flatten(x, 1)\n        x = F.relu(self.bn5(self.fc1(x)))\n        x = self.drop3(x)\n        x = self.fc2(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T02:26:34.722944Z","iopub.execute_input":"2026-02-16T02:26:34.723225Z","iopub.status.idle":"2026-02-16T02:26:34.730782Z","shell.execute_reply.started":"2026-02-16T02:26:34.723195Z","shell.execute_reply":"2026-02-16T02:26:34.730243Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class BigKernelCNN(nn.Module):\n    def __init__(self):\n        super(BigKernelCNN, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=5, padding=2)\n        self.bn1 = nn.BatchNorm2d(32)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, padding=2)\n        self.bn2 = nn.BatchNorm2d(64)\n        self.pool = nn.MaxPool2d(2)\n        self.fc1 = nn.Linear(64 * 7 * 7, 256)\n        self.fc2 = nn.Linear(256, 10)\n        self.dropout = nn.Dropout(0.5)\n\n    def forward(self, x):\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.pool(x)\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = self.pool(x)\n        x = torch.flatten(x, 1)\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        return self.fc2(x)\n\nclass ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=1):\n        super(ResidualBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_channels != out_channels:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),\n                nn.BatchNorm2d(out_channels)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(x)\n        return F.relu(out)\n\nclass ResNet5(nn.Module):\n    def __init__(self):\n        super(ResNet5, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n        self.layer1 = ResidualBlock(32, 32)\n        self.layer2 = ResidualBlock(32, 64, stride=2)\n        self.fc = nn.Linear(64 * 14 * 14, 10)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = torch.flatten(x, 1)\n        return self.fc(x)\n\nclass STNCNN(nn.Module):\n    def __init__(self):\n        super(STNCNN, self).__init__()\n        self.localization = nn.Sequential(\n            nn.Conv2d(1, 8, kernel_size=7),\n            nn.MaxPool2d(2, stride=2),\n            nn.ReLU(True),\n            nn.Conv2d(8, 10, kernel_size=5),\n            nn.MaxPool2d(2, stride=2),\n            nn.ReLU(True)\n        )\n        self.fc_loc = nn.Sequential(\n            nn.Linear(10 * 3 * 3, 32),\n            nn.ReLU(True),\n            nn.Linear(32, 3 * 2)\n        )\n        self.fc_loc[2].weight.data.zero_()\n        self.fc_loc[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n        self.fc1 = nn.Linear(64 * 5 * 5, 256)\n        self.fc2 = nn.Linear(256, 10)\n\n    def stn(self, x):\n        xs = self.localization(x)\n        xs = xs.view(-1, 10 * 3 * 3)\n        theta = self.fc_loc(xs).view(-1, 2, 3)\n        grid = F.affine_grid(theta, x.size(), align_corners=True)\n        x = F.grid_sample(x, grid, align_corners=True)\n        return x\n\n    def forward(self, x):\n        x = self.stn(x)\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n        x = torch.flatten(x, 1)\n        x = F.relu(self.fc1(x))\n        return self.fc2(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T02:26:34.732428Z","iopub.execute_input":"2026-02-16T02:26:34.733042Z","iopub.status.idle":"2026-02-16T02:26:34.749046Z","shell.execute_reply.started":"2026-02-16T02:26:34.733019Z","shell.execute_reply":"2026-02-16T02:26:34.748488Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"DEVICE = torch.device('cpu')\nif torch.cuda.is_available():\n    DEVICE = torch.device('cuda')\nelif torch.backends.mps.is_available():\n    DEVICE = torch.device('mps')\nprint(f\"Using device: {DEVICE}\")\n\ncriterion = nn.CrossEntropyLoss()\n\n# Mix of architectures for maximum diversity\narchitectures = [CNN, BigKernelCNN, ResNet5, STNCNN, CNN] \nmodels = []\noptimizers = []\nschedulers = []\n\nfor i, ArchClass in enumerate(architectures):\n    torch.manual_seed(42 + i)\n    model = ArchClass().to(DEVICE)\n    models.append(model)\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    optimizers.append(optimizer)\n    schedulers.append(optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2))\n\n# Track accuracy for weighting the final vote\nmodel_accuracies = [0.0] * len(models)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T02:26:34.749789Z","iopub.execute_input":"2026-02-16T02:26:34.750106Z","iopub.status.idle":"2026-02-16T02:26:34.799459Z","shell.execute_reply.started":"2026-02-16T02:26:34.750081Z","shell.execute_reply":"2026-02-16T02:26:34.798934Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Train","metadata":{}},{"cell_type":"code","source":"# Test\ndef test_model(model):\n    model.eval() # Set model to evaluation mode\n    correct = 0\n    total = 0\n    val_loss = 0.0\n    with torch.no_grad():\n        for data in val_loader:\n            images, labels = data\n            images = images.to(DEVICE)\n            labels = labels.to(DEVICE)\n            outputs = model(images)\n            loss = criterion(outputs, labels) # Calculate loss\n            val_loss += loss.item()\n            \n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    \n    avg_loss = val_loss / len(val_loader)\n    acc = 100 * correct / total\n    print(f'Accuracy: {acc:.2f}% | Val Loss: {avg_loss:.4f}')\n    return avg_loss, acc # Return this for the scheduler","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T02:26:34.800243Z","iopub.execute_input":"2026-02-16T02:26:34.800527Z","iopub.status.idle":"2026-02-16T02:26:34.805723Z","shell.execute_reply.started":"2026-02-16T02:26:34.800494Z","shell.execute_reply":"2026-02-16T02:26:34.805038Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train\nEPOCHS = 30\nfor m_idx, cnn in enumerate(models):\n    print(f\"Training Model {m_idx + 1}/{len(models)}...\")\n    optimizer = optimizers[m_idx]\n    scheduler = schedulers[m_idx]\n    \n    for epoch in range(EPOCHS):\n        cnn.train() # Set model back to training mode\n        running_loss = 0.0\n        for i, data in enumerate(train_loader, 0):\n            inputs, labels = data\n            inputs = inputs.to(DEVICE)\n            labels = labels.to(DEVICE)\n            optimizer.zero_grad()\n            outputs = cnn(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            # scheduler.step() # needed if using OneCycleLR\n    \n            running_loss += loss.item()\n            if i % 100 == 99:\n                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 100:.3f}')\n                running_loss = 0.0\n    \n        # Run validation and get the loss\n        current_val_loss, current_val_acc = test_model(cnn)\n        model_accuracies[m_idx] = max(model_accuracies[m_idx], current_val_acc)\n        \n        # Step the scheduler based on the validation loss\n        scheduler.step(current_val_loss)\n        \n        current_lr = optimizer.param_groups[0]['lr']\n        print(f'End of Epoch {epoch + 1} - Learning Rate: {current_lr}')\n\n    print(f'Finished Training Model {m_idx + 1}. Max Val Acc: {model_accuracies[m_idx]:.2f}%')\n\nprint('Finished Training')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T02:26:34.806465Z","iopub.execute_input":"2026-02-16T02:26:34.806719Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"# Convert accuracies to weights (normalized)\ntotal_acc = sum(model_accuracies)\nweights = [acc / total_acc for acc in model_accuracies]\n\nif test_loader is not None:\n    # Submission\n    submission_data = {'ImageId': [], 'Label': []}\n    \n    # Set all models to eval mode\n    for cnn in models:\n        cnn.eval()\n    \n    with torch.no_grad():\n        idx = 1\n        for images in test_loader:\n            images = images.to(DEVICE)\n            \n            # Initialize an empty tensor to store accumulated predictions\n            # Shape: [batch_size, num_classes]\n            ensemble_logits = torch.zeros((images.size(0), 10)).to(DEVICE) \n            \n            for cnn in models:\n                outputs = cnn(images)\n                ensemble_logits += outputs * weights[m_idx] # Summing the logits\n            \n            # Get the index of the max accumulated log-probability\n            _, predicted = torch.max(ensemble_logits, 1)\n    \n            preds = predicted.cpu().numpy()\n    \n            for p in preds:\n                submission_data['ImageId'].append(idx)\n                submission_data['Label'].append(p)\n                idx += 1\n    \n    # Save to csv\n    submission_df = pd.DataFrame(submission_data)\n    submission_df.to_csv('submission.csv', index=False)\n    print(\"Submission file saved!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Verification","metadata":{}},{"cell_type":"code","source":"if submission_df is not None:\n    # 1. Check for missing values\n    missing_values = submission_df.isnull().sum().sum()\n    \n    # 2. Check for correct label range (0-9)\n    invalid_labels = submission_df[(submission_df['Label'] < 0) | (submission_df['Label'] > 9)]\n    \n    # 3. Final Verification Report\n    print(\"--- Submission Verification ---\")\n    print(f\"Total Rows: {len(submission_df)}\")\n    print(f\"Missing Values: {missing_values}\")\n    print(f\"Invalid Labels Found: {len(invalid_labels)}\")\n    print(f\"Column Names: {list(submission_df.columns)}\")\n    \n    if len(submission_df) == len(base_test_df) and missing_values == 0 and len(invalid_labels) == 0:\n        print(\"\\n✅ Verification Passed! Your file is ready for submission.\")\n    else:\n        print(\"\\n❌ Verification Failed. Please check the counts above.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if submission_df is not None:\n    # Get one batch from the test loader\n    images = next(iter(test_loader))\n    outputs = cnn(images.to(DEVICE))\n    _, predicted = torch.max(outputs, 1)\n    \n    # Plot the first image in the batch\n    plt.imshow(images[0].reshape(28, 28), cmap='gray')\n    plt.title(f'Predicted Label: {predicted[0].item()}')\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}